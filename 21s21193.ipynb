{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S0qnhnnI-eh",
        "outputId": "3485b2af-53e0-454b-9fac-ee11d861cc03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#My dataset is available in googledrive; so I am accessing my drive from colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "#Once this is executed, you will see your drive appearing on the left hand side"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTP2yHcoKhzv"
      },
      "outputs": [],
      "source": [
        "# Define paths to the dataset\n",
        "train_dir = '/content/drive/MyDrive/train-cat-rabbit'  # Update with your actual path\n",
        "test_dir = '/content/drive/MyDrive/test-images'    # Update with your actual path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6pR-B96NSKh",
        "outputId": "2efeadfe-20a4-4c14-8a0c-8a16011a6d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n",
            "2\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(len(os.listdir('/content/drive/MyDrive/train-cat-rabbit')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/train-cat-rabbit')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/test-images')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/test-images')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn544UCQccwb",
        "outputId": "fee6f563-c976-4a65-d503-b66335e10d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1280 images belonging to 2 classes.\n",
            "Found 320 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create ImageDataGenerator for training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2  # Split 20% of the images for validation\n",
        ")\n",
        "\n",
        "# Load and prepare training data\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(256,256),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',  # 'binary' for binary classification (cats vs. dogs)\n",
        "    subset='training'  # Specify 'training' for the training set\n",
        ")\n",
        "\n",
        "# Create ImageDataGenerator for validation set\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2  # Note: Using the same validation split as in the training set\n",
        ")\n",
        "\n",
        "# Load and prepare validation data\n",
        "validation_data = validation_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(256,256),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'  # Specify 'validation' for the validation set\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQwO_F_Acxg0"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,UpSampling2D, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovIPU6aUc66z"
      },
      "outputs": [],
      "source": [
        "# create CNN model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))  # 32 filters\n",
        "#model.add(BatchNormalization())  # added to reduce overfitting\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "#model.add(BatchNormalization())  # added to reduce overfitting\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "#model.add(BatchNormalization())  # added to reduce overfitting\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation='relu')) #feature reduction\n",
        "#model.add(Dropout(0.1))  # added to reduce overfitting\n",
        "model.add(Dense(64,activation='relu'))\n",
        "#model.add(Dropout(0.1))  # added to reduce overfitting\n",
        "model.add(Dense(1,activation='sigmoid'))  #output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErWgjvxwdDAK"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy']) #binary_crossentropy - binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9QNWG9EdKei",
        "outputId": "c2903c3f-d93d-474e-ca64-1784039a60bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "40/40 [==============================] - 470s 12s/step - loss: 0.6964 - accuracy: 0.6164 - val_loss: 0.5180 - val_accuracy: 0.7156\n",
            "Epoch 2/30\n",
            "40/40 [==============================] - 200s 5s/step - loss: 0.4706 - accuracy: 0.7664 - val_loss: 0.4042 - val_accuracy: 0.8094\n",
            "Epoch 3/30\n",
            "40/40 [==============================] - 205s 5s/step - loss: 0.3164 - accuracy: 0.8469 - val_loss: 0.3509 - val_accuracy: 0.8313\n",
            "Epoch 4/30\n",
            "40/40 [==============================] - 208s 5s/step - loss: 0.2182 - accuracy: 0.9078 - val_loss: 0.3278 - val_accuracy: 0.8781\n",
            "Epoch 5/30\n",
            "40/40 [==============================] - 208s 5s/step - loss: 0.1287 - accuracy: 0.9484 - val_loss: 0.3540 - val_accuracy: 0.8687\n",
            "Epoch 6/30\n",
            "40/40 [==============================] - 191s 5s/step - loss: 0.1001 - accuracy: 0.9688 - val_loss: 0.3788 - val_accuracy: 0.8938\n",
            "Epoch 7/30\n",
            "40/40 [==============================] - 192s 5s/step - loss: 0.0519 - accuracy: 0.9844 - val_loss: 0.3485 - val_accuracy: 0.8938\n",
            "Epoch 8/30\n",
            "40/40 [==============================] - 202s 5s/step - loss: 0.0429 - accuracy: 0.9859 - val_loss: 0.3036 - val_accuracy: 0.9156\n",
            "Epoch 9/30\n",
            "40/40 [==============================] - 191s 5s/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.4316 - val_accuracy: 0.8906\n",
            "Epoch 10/30\n",
            "40/40 [==============================] - 190s 5s/step - loss: 0.0587 - accuracy: 0.9773 - val_loss: 0.4163 - val_accuracy: 0.8906\n",
            "Epoch 11/30\n",
            "40/40 [==============================] - 198s 5s/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.4238 - val_accuracy: 0.8906\n",
            "Epoch 12/30\n",
            "40/40 [==============================] - 186s 5s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.9187\n",
            "Epoch 13/30\n",
            "40/40 [==============================] - 190s 5s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.9156\n",
            "Epoch 14/30\n",
            "40/40 [==============================] - 199s 5s/step - loss: 3.4936e-04 - accuracy: 1.0000 - val_loss: 0.6028 - val_accuracy: 0.9156\n",
            "Epoch 15/30\n",
            "40/40 [==============================] - 189s 5s/step - loss: 2.0082e-04 - accuracy: 1.0000 - val_loss: 0.6214 - val_accuracy: 0.9187\n",
            "Epoch 16/30\n",
            "40/40 [==============================] - 187s 5s/step - loss: 1.4731e-04 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 0.9187\n",
            "Epoch 17/30\n",
            "40/40 [==============================] - 217s 5s/step - loss: 1.1114e-04 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.9187\n",
            "Epoch 18/30\n",
            "40/40 [==============================] - 197s 5s/step - loss: 9.1588e-05 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.9219\n",
            "Epoch 19/30\n",
            "40/40 [==============================] - 190s 5s/step - loss: 7.6006e-05 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.9187\n",
            "Epoch 20/30\n",
            "40/40 [==============================] - 188s 5s/step - loss: 6.0908e-05 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.9156\n",
            "Epoch 21/30\n",
            "40/40 [==============================] - 208s 5s/step - loss: 5.4074e-05 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.9250\n",
            "Epoch 22/30\n",
            "40/40 [==============================] - 191s 5s/step - loss: 4.3638e-05 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.9187\n",
            "Epoch 23/30\n",
            "40/40 [==============================] - 187s 5s/step - loss: 3.7182e-05 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.9156\n",
            "Epoch 24/30\n",
            "40/40 [==============================] - 207s 5s/step - loss: 3.3688e-05 - accuracy: 1.0000 - val_loss: 0.7275 - val_accuracy: 0.9156\n",
            "Epoch 25/30\n",
            "40/40 [==============================] - 190s 5s/step - loss: 2.9931e-05 - accuracy: 1.0000 - val_loss: 0.7329 - val_accuracy: 0.9125\n",
            "Epoch 26/30\n",
            "29/40 [====================>.........] - ETA: 48s - loss: 2.3318e-05 - accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_data, epochs=30, validation_data=validation_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}